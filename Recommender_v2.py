import streamlit as st
import joblib
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from datetime import datetime
import os
from huggingface_hub import hf_hub_download

# ==============================
# üèóÔ∏è FEATURE BUILDER CLASS - KH·ªöP V·ªöI MODEL TRAIN
# ==============================
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

class FeatureBuilder:
    """Class ƒë·ªÉ x√¢y d·ª±ng feature matrix - KH·ªöP 100% V·ªöI MODEL TRAIN"""
    
    def __init__(self):
        self.mm_scaler = MinMaxScaler()
        self.fitted = False
        self.expected_n_features = 8  # ‚úÖ TH√äM D√íNG N√ÄY
        
    def preprocess_df(self, df):
        """Ti·ªÅn x·ª≠ l√Ω dataframe - KH·ªöP V·ªöI CODE TRAIN"""
        df_proc = df.copy()
        
        # ============================================
        # 1) BASIC CLEANING
        # ============================================
        df_proc['price'] = df_proc['price'].clip(1, 500)
        df_proc['km_driven'] = df_proc['km_driven'].clip(0, 200000)
        df_proc['age'] = df_proc['age'].clip(0, 30)
        
        # Fill missing values
        df_proc['price'] = df_proc['price'].fillna(df_proc['price'].median())
        df_proc['km_driven'] = df_proc['km_driven'].fillna(df_proc['km_driven'].median())
        df_proc['age'] = df_proc['age'].fillna(df_proc['age'].median())
        
        # ============================================
        # 2) ENGINE CC - VIETNAM SPECIFIC
        # ============================================
        VN_CC_DICT = {
            "exciter":150, "r15":155, "r3":321, "r25":250,
            "sirius":110, "jupiter":110, "nouvo":135, "janus":125,
            "latte":125, "grande":125, "mio":110,
            "wave":110, "future":125, "dream":100, "cub":50,
            "winner":150, "winner x":150,
            "vision":110, "lead":125, "sh mode":125,
            "air blade":125, "airblade":125,
            "sh":125, "vario":160, "pcx":125, "click":125,
            "vespa":125, "primavera":125, "sprint":125,
            "raider":150, "satria":150, "gsx":150,
            "attila":125, "shark":125, "hayate":125,
            "cb150":150, "cbr150":150, "cbr250":250, "cbr300":300,
            "rebel":300, "shadow":750,
            "mt15":155, "mt03":321, "mt07":689,
            "z300":300, "z650":650, "ninja":300,
            "duke":200, "rc":200,
        }
        
        def extract_engine_cc(row):
            """Extract engine CC t·ª´ model name"""
            model = str(row.get('model', '')).lower()
            is_pkl = bool(row.get('xe_pkl', 0))
            
            # Check dictionary first
            for key, cc in VN_CC_DICT.items():
                if key in model:
                    return cc
            
            # Regex fallback
            import re
            patterns = [
                r'\b(50|70|90|100|110|125|150|155|200|250|300|350|400|500|650|750|1000)\b',
                r'(?:cb|cbr|mt|gsx|ninja|duke|rc)[\s-]?(\d{2,4})'
            ]
            
            for pat in patterns:
                matches = re.findall(pat, model)
                if matches:
                    vals = [int(v) for v in matches if str(v).isdigit()]
                    if vals:
                        cc = max(vals)
                        if 50 <= cc <= 1200:
                            return cc
            
            # Default values
            return 300 if is_pkl else 125
        
        df_proc['engine_cc'] = df_proc.apply(extract_engine_cc, axis=1)
        
        # ============================================
        # 3) VEHICLE TYPE MAPPING
        # ============================================
        mapping_vehicle = {
            "Xe s·ªë": 0,
            "Tay ga": 1,
            "Tay c√¥n/Moto": 2,
            "PKL": 2
        }
        df_proc['vehicle_type_num'] = df_proc['vehicle_type'].map(mapping_vehicle).fillna(1)
        
        # ============================================
        # 4) BOOLEAN FEATURES
        # ============================================
        for bcol in ['xe_pkl', 'xe_zin', 'xe_co', 'xe_da_thay_doi', 'xe_chinh_chu', 'xe_nang_cap']:
            if bcol not in df_proc.columns:
                df_proc[bcol] = 0
            df_proc[bcol] = df_proc[bcol].astype(int)
        
        # ============================================
        # 5) LOG TRANSFORMS
        # ============================================
        df_proc['log_km'] = np.log1p(df_proc['km_driven'])  # ‚Üê T√äN ƒê√öNG: log_km
        df_proc['log_price'] = np.log1p(df_proc['price'])
        
        # ============================================
        # 6) DERIVED FEATURES
        # ============================================
        df_proc['km_per_year'] = df_proc['km_driven'] / (df_proc['age'] + 1)
        df_proc['log_km_per_year'] = np.log1p(df_proc['km_per_year'])
        
        # power_ratio = engine_cc / (price + 1)
        df_proc['power_ratio'] = df_proc['engine_cc'] / (df_proc['price'] + 1)
        
        # price_per_cc = price / (engine_cc + 1)
        df_proc['price_per_cc'] = df_proc['price'] / (df_proc['engine_cc'] + 1)
        
        # ============================================
        # 7) ENGINE CLASS (CATEGORICAL ‚Üí NUMERIC)
        # ============================================
        bins = [0, 150, 300, 650, 2000]
        labels = [1, 2, 3, 4]
        df_proc['engine_class'] = pd.cut(
            df_proc['engine_cc'], 
            bins=bins, 
            labels=labels, 
            include_lowest=True
        )
        df_proc['engine_class'] = df_proc['engine_class'].fillna(1).astype(int)
        
        # ============================================
        # 8) PRICE MINMAX NORMALIZATION
        # ============================================
        # Fit scaler on first call
        if not self.fitted:
            self.mm_scaler.fit(df_proc[['price']])
            self.fitted = True
        
        df_proc['price_minmax'] = self.mm_scaler.transform(df_proc[['price']]).ravel()
        
        return df_proc
    
    def fit(self, df):
        """Fit (kh√¥ng c·∫ßn thi·∫øt cho rule-based, nh∆∞ng gi·ªØ ƒë·ªÉ t∆∞∆°ng th√≠ch)"""
        return self
    
    def transform(self, df):
        """Transform (ƒë√£ l√†m trong preprocess_df)"""
        return df
    
    def fit_transform(self, df):
        """Fit v√† transform"""
        return self.preprocess_df(df)


    def build_feature_matrix(self, df):
        """
        Build feature matrix - AUTO-DETECT s·ªë features
        """
        
        # Th·ª≠ c√°c feature sets theo th·ª© t·ª±
        feature_sets = {
            "BASE_6": [
                "log_price", "log_km", "age", 
                "log_km_per_year", "engine_cc", "vehicle_type_num"
            ],
            "V4_MINMAX_6": [
                "price_minmax", "log_km", "engine_cc",
                "engine_class", "vehicle_type_num", "power_ratio"
            ],
            "V4_BOOL_7": [
                "price_minmax", "log_km", "engine_cc", "engine_class",
                "vehicle_type_num", "power_ratio", "xe_pkl"
            ],
            "V4_BOOL_8": [
                "price_minmax", "log_km", "engine_cc", "engine_class",
                "vehicle_type_num", "power_ratio", "xe_pkl", "xe_zin"
            ]
        }
        
        # L·∫•y expected features t·ª´ model n·∫øu c√≥
        expected_n_features = getattr(self, 'expected_n_features', 8)
        
        # Ch·ªçn feature set ph√π h·ª£p
        for name, feats in feature_sets.items():
            if len(feats) == expected_n_features:
                feature_names = feats
                # st.info(f"‚úÖ Using feature set: {name} ({len(feats)} features)")
                break
        else:
            # Default fallback
            feature_names = feature_sets["V4_BOOL_7"]
            st.warning(f"‚ö†Ô∏è Using default: V4_BOOL_7")
        
        # Build features
        features = []
        for col in feature_names:
            if col in df.columns:
                values = df[col].values.reshape(-1, 1)
                values = np.nan_to_num(values, nan=0.0, posinf=0.0, neginf=0.0)
                features.append(values)
            else:
                st.error(f"‚ùå Missing column: {col}")
                features.append(np.zeros((len(df), 1)))
        
        X = np.hstack(features)
        
        # st.info(f"üìä Built feature matrix: {X.shape}")
        
        return X

# Page config
st.set_page_config(page_title="Bu√¥n B√°n Xe M√°y", page_icon="üèçÔ∏è", layout="wide")


# ==============================
# üîÑ SCROLL TO TOP FUNCTION
# ==============================
def scroll_to_top():
    """JavaScript ƒë·ªÉ cu·ªôn l√™n ƒë·∫ßu trang"""
    st.components.v1.html(
        """
        <script>
            window.parent.document.querySelector('section.main').scrollTo(0, 0);
        </script>
        """,
        height=0,
    )


# ==============================
# üñºÔ∏è BANNER TI√äU ƒê·ªÄ ·ªû ƒê·∫¶U TRANG
# ==============================
if os.path.exists("banner.jpg"):
    st.image("banner.jpg", use_column_width=True)
else:
    st.markdown(
        """
    <div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px;'>
        <h1 style='color: white; margin: 0;'>üèçÔ∏è H·ªÜ TH·ªêNG BU√îN B√ÅN XE M√ÅY</h1>
        <p style='color: white; margin: 10px 0 0 0;'>T√¨m ki·∫øm v√† g·ª£i √Ω xe m√°y th√¥ng minh</p>
    </div>
    """,
        unsafe_allow_html=True,
    )
    st.markdown("<br>", unsafe_allow_html=True)


# ==============================
# üì• DOWNLOAD FROM HUGGING FACE
# ==============================
def download_from_huggingface(repo_id, filename, cache_dir="./model_cache"):
    """
    Download file t·ª´ Hugging Face Hub

    Args:
        repo_id: ID c·ªßa repository tr√™n Hugging Face (vd: "username/repo-name")
        filename: T√™n file c·∫ßn download
        cache_dir: Th∆∞ m·ª•c l∆∞u cache

    Returns:
        str: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ƒë√£ download
    """
    try:
        # T·∫°o th∆∞ m·ª•c cache n·∫øu ch∆∞a c√≥
        os.makedirs(cache_dir, exist_ok=True)

        # Download file
        file_path = hf_hub_download(
            repo_id=repo_id,
            filename=filename,
            cache_dir=cache_dir,
            resume_download=True,
        )

        return file_path

    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i {filename}: {str(e)}")
        return None


@st.cache_resource
# Th√™m ƒëo·∫°n n√†y TR∆Ø·ªöC h√†m load_model() ƒë·ªÉ test
def check_files_exist():
    """Ki·ªÉm tra c√°c file c√≥ t·ªìn t·∫°i kh√¥ng"""
    from huggingface_hub import list_repo_files
    
    REPO_ID = "Mayer1226/Recommendation"
    
    try:
        files = list_repo_files(repo_id=REPO_ID)
        st.write("üìÅ **C√°c file trong repository:**")
        for f in files:
            st.write(f"- {f}")
        return files
    except Exception as e:
        st.error(f"L·ªói: {e}")
        return []

# G·ªçi h√†m n√†y ƒë·ªÉ ki·ªÉm tra
# if st.button("üîç Ki·ªÉm tra files tr√™n Hugging Face"):
#     check_files_exist()
@st.cache_resource(show_spinner=False)
def load_model():
    """Load model v√† dataframe t·ª´ Hugging Face - S·ª¨ D·ª§NG CLUSTERING ML"""
    
    REPO_ID = "Mayer1226/Recommendation"
    MODEL_FILENAME = "model_v4_20251121_202731.joblib"
    DF_FILENAME = "df_items_20251121_202731.joblib"
    CLUSTER_FILENAME = "motorbike_cluster_model.joblib"
    
    try:
        with st.spinner("üîÑ ƒêang t·∫£i d·ªØ li·ªáu t·ª´ Hugging Face..."):
            # Download files
            model_path = download_from_huggingface(REPO_ID, MODEL_FILENAME)
            df_path = download_from_huggingface(REPO_ID, DF_FILENAME)
            cluster_model_path = download_from_huggingface(REPO_ID, CLUSTER_FILENAME)
            
            if not all([model_path, df_path, cluster_model_path]):
                st.error("‚ùå Kh√¥ng th·ªÉ t·∫£i ƒë·∫ßy ƒë·ªß files")
                st.stop()
            
            # Load models
            model = joblib.load(model_path)
            df = joblib.load(df_path)
            df = df.reset_index(drop=True)
            
            cluster_package = joblib.load(cluster_model_path)
            
            # st.success(f"‚úÖ Loaded {len(df):,} xe v√† clustering model!")
            
            # ============================================
            # APPLY CLUSTERING WITH NEW FEATUREBUILDER
            # ============================================
            
            try:
                # st.info("üîÑ ƒêang ph√¢n lo·∫°i xe b·∫±ng ML clustering...")
                
                # Extract components
                cluster_scaler = cluster_package.get("scaler")
                cluster_kmeans = cluster_package.get("kmeans")
                cluster_labels = cluster_package.get("cluster_labels")
                
                # Create NEW FeatureBuilder (kh·ªõp v·ªõi model train)
                cluster_feature_builder = FeatureBuilder()
                
                # Step 1: Preprocess
                df_proc = cluster_feature_builder.preprocess_df(df)
                
                # Step 2: Build features
                Xc = cluster_feature_builder.build_feature_matrix(df_proc)
                
                # Step 3: Validate
                expected_features = cluster_scaler.n_features_in_
                actual_features = Xc.shape[1]
                
                # st.info(f"üìä Features: {actual_features} (expected: {expected_features})")
                
                if actual_features != expected_features:
                    st.error(f"‚ùå Feature mismatch: {actual_features} vs {expected_features}")
                    
                    # Show details
                    with st.expander("üîç Chi ti·∫øt features"):
                        st.write(f"**Actual shape:** {Xc.shape}")
                        st.write(f"**Expected:** {expected_features}")
                        st.write(f"**Sample values (first row):**")
                        st.code(Xc[0])
                    
                    # Fallback to rule-based
                    st.warning("‚ö†Ô∏è S·ª≠ d·ª•ng ph√¢n lo·∫°i rule-based")
                    df = apply_rule_based_clustering(df)
                    
                else:
                    # Step 4: Transform v√† predict
                    Xc_scaled = cluster_scaler.transform(Xc)
                    df["cluster_id"] = cluster_kmeans.predict(Xc_scaled)
                    df["cluster_name"] = df["cluster_id"].map(cluster_labels)
                    
                    # Validate results
                    n_clusters = df["cluster_id"].nunique()
                    cluster_dist = df["cluster_name"].value_counts().to_dict()
                    
                    st.success(f"‚úÖ ML Clustering th√†nh c√¥ng: {n_clusters} ph√¢n kh√∫c!")
                    st.info(f"üìä Ph√¢n b·ªë: {cluster_dist}")
                
            except Exception as cluster_error:
                # st.error(f"‚ùå L·ªói clustering: {str(cluster_error)}")
                
                # with st.expander("üîç Chi ti·∫øt l·ªói"):
                #     import traceback
                #     st.code(traceback.format_exc())
                
                # Fallback
                # st.warning("‚ö†Ô∏è S·ª≠ d·ª•ng ph√¢n lo·∫°i rule-based")
                df = apply_rule_based_clustering(df)
            
            # ============================================
            # ADD METADATA
            # ============================================
            
            cluster_colors = {
                0: "#f94144",
                1: "#f3722c",
                2: "#f9c74f",
                3: "#90be6d",
                4: "#577590",
            }
            df["cluster_color"] = df["cluster_id"].map(cluster_colors).fillna("#667eea")
            
            current_year = datetime.now().year
            df["registration_year"] = current_year - df["age"]
            
            cluster_package["cluster_colors"] = cluster_colors
            cluster_package["feature_builder"] = cluster_feature_builder
            
            return model, df, cluster_package
            
    except Exception as e:
        st.error(f"‚ùå L·ªói khi load model: {str(e)}")
        
        # with st.expander("üîç Chi ti·∫øt l·ªói ƒë·∫ßy ƒë·ªß"):
        #     import traceback
        #     st.code(traceback.format_exc())
        
        st.stop()


def apply_rule_based_clustering(df):
    """Fallback: Rule-based clustering n·∫øu ML fail"""
    
    def classify_motorbike(row):
        price = row['price']
        age = row['age']
        km = row['km_driven']
        vehicle_type = str(row.get('vehicle_type', ''))
        
        if price > 80 or 'PKL' in vehicle_type or 'Moto' in vehicle_type:
            return 4
        elif 25 <= price <= 80 and age <= 10:
            return 0
        elif km < 5000 and age >= 5:
            return 2
        elif age > 15 or (vehicle_type == 'Xe s·ªë' and price < 15):
            return 1
        else:
            return 3
    
    df['cluster_id'] = df.apply(classify_motorbike, axis=1)
    
    cluster_labels = {
        0: "Xe Ph·ªï Th√¥ng Cao C·∫•p",
        1: "Xe S·ªë C≈© ‚Äì Kinh T·∫ø",
        2: "Xe √çt S·ª≠ D·ª•ng ‚Äì C√≤n M·ªõi",
        3: "Xe Ph·ªï Th√¥ng ‚Äì ƒê√£ Qua S·ª≠ D·ª•ng",
        4: "Xe Cao C·∫•p & PKL"
    }
    
    df['cluster_name'] = df['cluster_id'].map(cluster_labels)
    
    return df


def handle_multiselect_with_all(selected):
    """X·ª≠ l√Ω logic 'T·∫•t c·∫£' trong multiselect"""
    if not selected:
        return ["T·∫•t c·∫£"]

    if "T·∫•t c·∫£" in selected and len(selected) > 1:
        if selected[-1] == "T·∫•t c·∫£":
            return ["T·∫•t c·∫£"]
        else:
            return [x for x in selected if x != "T·∫•t c·∫£"]

    return selected


def search_items(query, df, top_k=10):
    """T√¨m ki·∫øm xe theo query"""
    if len(df) == 0:
        return pd.DataFrame()

    if not query.strip():
        results = df.head(top_k).copy()
        results["position"] = results.index
        return results

    df["search_text"] = (
        df["brand"].fillna("")
        + " "
        + df["model"].fillna("")
        + " "
        + df["vehicle_type"].fillna("")
        + " "
        + df["description_norm"].fillna("")
    )

    try:
        vectorizer = TfidfVectorizer(max_features=5000)
        tfidf_matrix = vectorizer.fit_transform(df["search_text"])
        query_vec = vectorizer.transform([query])

        scores = cosine_similarity(query_vec, tfidf_matrix).flatten()
        top_indices = scores.argsort()[::-1][:top_k]

        results = df.iloc[top_indices].copy()
        results["search_score"] = scores[top_indices]
        results["position"] = top_indices

        return results
    except:
        return pd.DataFrame()


def apply_filters(
    df, brands, models, price_range, vehicle_types, locations, engine_capacities
):
    """√Åp d·ª•ng b·ªô l·ªçc"""
    filtered = df.copy()

    if brands and "T·∫•t c·∫£" not in brands:
        filtered = filtered[filtered["brand"].isin(brands)]

    if models and "T·∫•t c·∫£" not in models:
        filtered = filtered[filtered["model"].isin(models)]

    if vehicle_types and "T·∫•t c·∫£" not in vehicle_types:
        filtered = filtered[filtered["vehicle_type"].isin(vehicle_types)]

    if locations and "T·∫•t c·∫£" not in locations:
        filtered = filtered[filtered["location"].isin(locations)]

    if engine_capacities and "T·∫•t c·∫£" not in engine_capacities:
        filtered = filtered[filtered["engine_capacity"].isin(engine_capacities)]

    if price_range[0] is not None and price_range[1] is not None:
        filtered = filtered[
            (filtered["price"] >= price_range[0])
            & (filtered["price"] <= price_range[1])
        ]

    return filtered


def get_recommendations(item_position, model, df, top_k=3):
    """L·∫•y xe t∆∞∆°ng t·ª±"""
    sim_scores = model["similarity"][item_position].copy()
    sim_scores[item_position] = -10.0
    top_indices = sim_scores.argsort()[::-1][:top_k]

    recs = df.iloc[top_indices].copy()
    recs["similarity"] = sim_scores[top_indices]
    recs["position"] = top_indices

    return recs


def show_about_page():
    """Trang gi·ªõi thi·ªáu"""
    st.title("üìñ Gi·ªõi Thi·ªáu V·ªÅ H·ªá Th·ªëng")

    st.markdown("---")

    # M·ª•c ƒë√≠ch
    st.markdown("## üéØ M·ª•c ƒê√≠ch")
    st.markdown(
        """
    H·ªá th·ªëng **Bu√¥n B√°n Xe M√°y** ƒë∆∞·ª£c x√¢y d·ª±ng nh·∫±m:
    
    - üîç **T√¨m ki·∫øm th√¥ng minh**: Gi√∫p ng∆∞·ªùi d√πng d·ªÖ d√†ng t√¨m ki·∫øm xe m√°y ph√π h·ª£p v·ªõi nhu c·∫ßu
    - üéØ **G·ª£i √Ω c√° nh√¢n h√≥a**: ƒê·ªÅ xu·∫•t c√°c xe t∆∞∆°ng t·ª± d·ª±a tr√™n s·ªü th√≠ch v√† l·ª±a ch·ªçn c·ªßa ng∆∞·ªùi d√πng
    - üìä **L·ªçc ƒëa ti√™u ch√≠**: H·ªó tr·ª£ l·ªçc theo nhi·ªÅu ti√™u ch√≠ nh∆∞ h√£ng xe, gi√°, khu v·ª±c, dung t√≠ch ƒë·ªông c∆°...
    - üí° **Tr·∫£i nghi·ªám t·ªët nh·∫•t**: Cung c·∫•p giao di·ªán th√¢n thi·ªán, d·ªÖ s·ª≠ d·ª•ng cho m·ªçi ƒë·ªëi t∆∞·ª£ng ng∆∞·ªùi d√πng
    """
    )

    st.markdown("---")

    # T√≠nh nƒÉng ch√≠nh
    st.markdown("## ‚ú® T√≠nh NƒÉng Ch√≠nh")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown(
            """
        ### üîé T√¨m Ki·∫øm & L·ªçc
        - T√¨m ki·∫øm theo t·ª´ kh√≥a t·ª± do
        - L·ªçc theo h√£ng xe, model
        - L·ªçc theo lo·∫°i xe, khu v·ª±c
        - L·ªçc theo dung t√≠ch ƒë·ªông c∆°
        - L·ªçc theo kho·∫£ng gi√°
        """
        )

        st.markdown(
            """
        ### üìã Hi·ªÉn Th·ªã Th√¥ng Tin
        - Th√¥ng tin chi ti·∫øt t·ª´ng xe
        - Gi√° c·∫£, s·ªë km ƒë√£ ƒëi
        - NƒÉm ƒëƒÉng k√Ω, xu·∫•t x·ª©
        - M√¥ t·∫£ chi ti·∫øt s·∫£n ph·∫©m
        """
        )

    with col2:
        st.markdown(
            """
        ### üéØ H·ªá Th·ªëng G·ª£i √ù
        - G·ª£i √Ω xe t∆∞∆°ng t·ª±
        - T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng
        - ƒê·ªÅ xu·∫•t d·ª±a tr√™n ƒë·∫∑c ƒëi·ªÉm xe
        - C√° nh√¢n h√≥a tr·∫£i nghi·ªám
        """
        )

        st.markdown(
            """
        ### üíª Giao Di·ªán Ng∆∞·ªùi D√πng
        - Thi·∫øt k·∫ø responsive
        - D·ªÖ d√†ng ƒëi·ªÅu h∆∞·ªõng
        - Hi·ªÉn th·ªã tr·ª±c quan
        - T∆∞∆°ng t√°c m∆∞·ª£t m√†
        """
        )

    st.markdown("---")

    # C√¥ng ngh·ªá
    st.markdown("## üõ†Ô∏è C√¥ng Ngh·ªá S·ª≠ D·ª•ng")

    st.markdown(
        """
    ### üìö Th∆∞ Vi·ªán & Framework
    """
    )

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown(
            """
        **Frontend & UI**
        - üé® **Streamlit**: Framework web app
        - üìä **Pandas**: X·ª≠ l√Ω d·ªØ li·ªáu
        - üî¢ **NumPy**: T√≠nh to√°n s·ªë h·ªçc
        """
        )

    with col2:
        st.markdown(
            """
        **Machine Learning**
        - ü§ñ **Scikit-learn**: Thu·∫≠t to√°n ML
        - üìù **TF-IDF**: Vector h√≥a vƒÉn b·∫£n
        - üìè **Cosine Similarity**: T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng
        """
        )

    with col3:
        st.markdown(
            """
        **L∆∞u Tr·ªØ & X·ª≠ L√Ω**
        - üíæ **Joblib**: L∆∞u/load model
        - ü§ó **Hugging Face**: Cloud storage
        - ‚è∞ **Datetime**: X·ª≠ l√Ω th·ªùi gian
        """
        )

    st.markdown("---")

    # Thu·∫≠t to√°n
    st.markdown("## üß† Thu·∫≠t To√°n G·ª£i √ù")

    st.markdown(
        """
    H·ªá th·ªëng s·ª≠ d·ª•ng **Content-Based Filtering** v·ªõi c√°c b∆∞·ªõc:
    
    1. **Vector h√≥a ƒë·∫∑c ƒëi·ªÉm**: Chuy·ªÉn ƒë·ªïi th√¥ng tin xe th√†nh vector s·ªë
    2. **TF-IDF**: Tr√≠ch xu·∫•t ƒë·∫∑c ƒëi·ªÉm quan tr·ªçng t·ª´ m√¥ t·∫£ v√† th√¥ng tin xe
    3. **Cosine Similarity**: T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c xe
    4. **Ranking**: S·∫Øp x·∫øp v√† ƒë·ªÅ xu·∫•t xe c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t
    """
    )

    # Visualization of similarity
    st.info(
        """
    üí° **V√≠ d·ª•**: Khi b·∫°n xem m·ªôt chi·∫øc Honda Wave Alpha, h·ªá th·ªëng s·∫Ω t√¨m c√°c xe c√≥:
    - C√πng h√£ng ho·∫∑c ph√¢n kh√∫c t∆∞∆°ng t·ª±
    - Gi√° c·∫£ g·∫ßn nhau
    - Dung t√≠ch ƒë·ªông c∆° t∆∞∆°ng ƒë∆∞∆°ng
    - ƒê·∫∑c ƒëi·ªÉm k·ªπ thu·∫≠t gi·ªëng nhau
    """
    )

    st.markdown("---")

    # Th·ªëng k√™
    st.markdown("## üìä Th·ªëng K√™ H·ªá Th·ªëng")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("üèçÔ∏è T·ªïng s·ªë xe", f"{len(df):,}")

    with col2:
        st.metric("üè¢ S·ªë h√£ng xe", f"{df['brand'].nunique()}")

    with col3:
        st.metric("üè∑Ô∏è S·ªë lo·∫°i xe", f"{df['vehicle_type'].nunique()}")

    with col4:
        st.metric("üìç S·ªë khu v·ª±c", f"{df['location'].nunique()}")

    st.markdown("---")

    # H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
    st.markdown("## üìñ H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng")

    with st.expander("üîç C√°ch t√¨m ki·∫øm xe"):
        st.markdown(
            """
        1. Nh·∫≠p t·ª´ kh√≥a v√†o √¥ t√¨m ki·∫øm (t√™n xe, h√£ng, lo·∫°i xe...)
        2. S·ª≠ d·ª•ng b·ªô l·ªçc ƒë·ªÉ thu h·∫πp k·∫øt qu·∫£
        3. Nh·∫•n n√∫t "T√¨m ki·∫øm" ho·∫∑c Enter
        4. Xem danh s√°ch k·∫øt qu·∫£ ph√π h·ª£p
        """
        )

    with st.expander("üéØ C√°ch s·ª≠ d·ª•ng b·ªô l·ªçc"):
        st.markdown(
            """
        1. M·ªü r·ªông ph·∫ßn "B·ªô L·ªçc T√¨m Ki·∫øm"
        2. Ch·ªçn c√°c ti√™u ch√≠: H√£ng xe, Model, Lo·∫°i xe, Khu v·ª±c, Dung t√≠ch
        3. ƒêi·ªÅu ch·ªânh kho·∫£ng gi√° mong mu·ªën
        4. K·∫øt qu·∫£ s·∫Ω t·ª± ƒë·ªông c·∫≠p nh·∫≠t
        """
        )

    with st.expander("üëÅÔ∏è C√°ch xem chi ti·∫øt v√† xe t∆∞∆°ng t·ª±"):
        st.markdown(
            """
        1. Nh·∫•n n√∫t "Xem chi ti·∫øt" tr√™n xe b·∫°n quan t√¢m
        2. Xem ƒë·∫ßy ƒë·ªß th√¥ng tin chi ti·∫øt c·ªßa xe
        3. Cu·ªôn xu·ªëng ph·∫ßn "Xe T∆∞∆°ng T·ª±" ƒë·ªÉ xem g·ª£i √Ω
        4. Nh·∫•n "Xem chi ti·∫øt" tr√™n xe g·ª£i √Ω ƒë·ªÉ kh√°m ph√° th√™m
        """
        )

    st.markdown("---")

    # Call to action
    st.markdown("## üöÄ B·∫Øt ƒê·∫ßu Ngay")

    col1, col2, col3 = st.columns([1, 2, 1])

    with col2:
        if st.button(
            "üîç ƒêi ƒë·∫øn Trang T√¨m Ki·∫øm", use_container_width=True, type="primary"
        ):
            st.session_state["page"] = "search"
            st.session_state["scroll_to_top"] = True
            st.rerun()

    st.markdown("---")

    # Footer
    st.markdown(
        """
    <div style='text-align: center; color: #666; padding: 20px;'>
        <p>üí° ƒê∆∞·ª£c ph√°t tri·ªÉn b·ªüi Ho√†ng Ph√∫c & B√≠ch Th·ªßy</p>
        <p>üìß Li√™n h·ªá h·ªó tr·ª£: phucthuy@buonbanxemay.vn</p>
    </div>
    """,
        unsafe_allow_html=True,
    )


def show_search_page():
    """Trang t√¨m ki·∫øm"""
    st.title("üèçÔ∏è T√¨m Ki·∫øm Xe M√°y")

    # Filters section
    with st.expander("üîß B·ªô L·ªçc T√¨m Ki·∫øm", expanded=False):
        # Row 1: 4 main filters
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            all_brands = ["T·∫•t c·∫£"] + sorted(df["brand"].unique().tolist())
            selected_brands_raw = st.multiselect(
                "üè¢ H√£ng xe",
                options=all_brands,
                default=["T·∫•t c·∫£"],
                key="filter_brands",
            )
            selected_brands = handle_multiselect_with_all(selected_brands_raw)

        with col2:
            if selected_brands and "T·∫•t c·∫£" not in selected_brands:
                available_models = (
                    df[df["brand"].isin(selected_brands)]["model"].unique().tolist()
                )
            else:
                available_models = df["model"].unique().tolist()

            all_models = ["T·∫•t c·∫£"] + sorted(available_models)
            selected_models_raw = st.multiselect(
                "üèçÔ∏è Model xe",
                options=all_models,
                default=["T·∫•t c·∫£"],
                key="filter_models",
            )
            selected_models = handle_multiselect_with_all(selected_models_raw)

        with col3:
            all_vehicle_types = ["T·∫•t c·∫£"] + sorted(
                df["vehicle_type"].unique().tolist()
            )
            selected_vehicle_types_raw = st.multiselect(
                "üè∑Ô∏è Lo·∫°i xe",
                options=all_vehicle_types,
                default=["T·∫•t c·∫£"],
                key="filter_vehicle_types",
            )
            selected_vehicle_types = handle_multiselect_with_all(
                selected_vehicle_types_raw
            )

        with col4:
            all_locations = ["T·∫•t c·∫£"] + sorted(df["location"].unique().tolist())
            selected_locations_raw = st.multiselect(
                "üìç Khu v·ª±c",
                options=all_locations,
                default=["T·∫•t c·∫£"],
                key="filter_locations",
            )
            selected_locations = handle_multiselect_with_all(selected_locations_raw)

        st.markdown("---")

        # Row 2: Engine capacity and price range
        col5, col6, col7 = st.columns([2, 3, 1])

        with col5:
            all_engine_capacities = ["T·∫•t c·∫£"] + sorted(
                df["engine_capacity"].unique().tolist()
            )
            selected_engine_capacities_raw = st.multiselect(
                "‚öôÔ∏è Dung t√≠ch",
                options=all_engine_capacities,
                default=["T·∫•t c·∫£"],
                key="filter_engine_capacities",
            )
            selected_engine_capacities = handle_multiselect_with_all(
                selected_engine_capacities_raw
            )

        with col6:
            col_price1, col_price2 = st.columns(2)
            with col_price1:
                min_price_input = st.number_input(
                    "üí∞ Gi√° t·ª´ (tri·ªáu)",
                    min_value=0.0,
                    max_value=float(df["price"].max()),
                    value=float(df["price"].min()),
                    step=1.0,
                    key="filter_min_price",
                    label_visibility="visible",
                )
            with col_price2:
                max_price_input = st.number_input(
                    "üí∞ Gi√° ƒë·∫øn (tri·ªáu)",
                    min_value=0.0,
                    max_value=float(df["price"].max()),
                    value=float(df["price"].max()),
                    step=1.0,
                    key="filter_max_price",
                    label_visibility="visible",
                )

    st.markdown("---")

    # Search bar
    col1, col2 = st.columns([4, 1])
    with col1:
        query = st.text_input(
            "üîç T√¨m ki·∫øm xe",
            value="",
            placeholder="Nh·∫≠p t√™n xe, h√£ng, lo·∫°i xe...",
            key="search_query",
        )
    with col2:
        st.write("")
        st.write("")
        search_btn = st.button("T√¨m ki·∫øm", use_container_width=True, type="primary")

    # X√°c ƒë·ªãnh query ƒë·ªÉ s·ª≠ d·ª•ng
    if query:
        current_query = query
    elif st.session_state.get("last_query", ""):
        current_query = st.session_state["last_query"]
    else:
        current_query = ""

    # √Åp d·ª•ng b·ªô l·ªçc
    price_range = (min_price_input, max_price_input)
    filtered_df = apply_filters(
        df,
        selected_brands,
        selected_models,
        price_range,
        selected_vehicle_types,
        selected_locations,
        selected_engine_capacities,
    )

    # T√¨m ki·∫øm trong filtered_df
    if current_query:
        results = search_items(current_query, filtered_df, top_k=10)
    else:
        results = filtered_df.head(10).copy()
        results["position"] = results.index

    # C·∫≠p nh·∫≠t last_query khi c√≥ query m·ªõi
    if query:
        st.session_state["last_query"] = query

    # Hi·ªÉn th·ªã query hi·ªán t·∫°i ƒëang ƒë∆∞·ª£c t√¨m ki·∫øm
    if current_query:
        st.info(f"üîç ƒêang t√¨m ki·∫øm: **{current_query}**")

    # Ki·ªÉm tra n·∫øu kh√¥ng c√≥ xe n√†o
    if len(results) == 0:
        st.warning(
            "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y xe ph√π h·ª£p. Vui l√≤ng th·ª≠ ƒëi·ªÅu ch·ªânh b·ªô l·ªçc ho·∫∑c t·ª´ kh√≥a."
        )
        return

    st.session_state["search_results"] = results

    st.markdown("---")
    st.subheader(f"üìã K·∫øt qu·∫£ ({len(results)} xe)")

    for idx, row in results.iterrows():
        with st.container():
            col_a, col_b = st.columns([4, 1])

            with col_a:
                st.markdown(f"### {row['brand']} {row['model']}")
                
                # Cluster badge - CH·ªà HI·ªÇN TH·ªä M·ªòT L·∫¶N
                st.markdown(
                    f"""
                    <span style="
                        background-color:{row['cluster_color']};
                        color:white;
                        padding:5px 10px;
                        border-radius:5px;
                        display:inline-block;
                        margin-bottom:10px;">
                        üöÄ {row['cluster_name']}
                    </span>
                    """,
                    unsafe_allow_html=True,
                )

                st.markdown(
                    f"**üí∞ Gi√°:** {row['price']:.1f} tri·ªáu VNƒê | **üìè S·ªë km ƒë√£ ƒëi:** {row['km_driven']:,} km | **üìÖ NƒÉm ƒëƒÉng k√Ω:** {int(row['registration_year'])}"
                )
                st.markdown(
                    f"**üè¢ Th∆∞∆°ng hi·ªáu:** {row['brand']} | **üè∑Ô∏è Lo·∫°i xe:** {row['vehicle_type']} | **‚öôÔ∏è Dung t√≠ch:** {row['engine_capacity']}"
                )
                st.markdown(
                    f"**üåç Xu·∫•t x·ª©:** {row['origin']} | **üìç ƒê·ªãa ƒëi·ªÉm:** {row['location']}"
                )

                if pd.notna(row["description_norm"]) and row["description_norm"]:
                    desc_short = (
                        row["description_norm"][:150] + "..."
                        if len(row["description_norm"]) > 150
                        else row["description_norm"]
                    )
                    st.markdown(f"**üìù M√¥ t·∫£:** {desc_short}")

            with col_b:
                st.write("")
                st.write("")
                if st.button("Xem chi ti·∫øt", key=f"view_{int(row['position'])}_{idx}"):
                    st.session_state["page"] = "detail"
                    st.session_state["selected_position"] = int(row["position"])
                    st.session_state["scroll_to_top"] = True
                    st.rerun()

            st.markdown("---")


def show_detail_page():
    """Trang chi ti·∫øt xe"""
    item_position = st.session_state["selected_position"]

    if item_position < 0 or item_position >= len(df):
        st.error("Xe kh√¥ng t·ªìn t·∫°i!")
        if st.button("‚Üê Quay l·∫°i"):
            st.session_state["page"] = "search"
            st.session_state["scroll_to_top"] = True
            st.rerun()
        return

    item = df.iloc[item_position]

    # Back button
    if st.button("‚Üê Quay l·∫°i t√¨m ki·∫øm"):
        st.session_state["page"] = "search"
        st.session_state["scroll_to_top"] = True
        st.rerun()

    st.markdown("---")

    # Title
    st.title(f"{item['brand']} {item['model']}")
    
    # Cluster badge
    st.markdown(
        f"""
        <div style="
            background-color:{item['cluster_color']};
            display:inline-block;
            color:white;
            padding:8px 15px;
            border-radius:6px;
            font-weight:bold;
            margin-top:5px;
            margin-bottom:15px;">
            üöÄ Thu·ªôc c·ª•m: {item['cluster_name']}
        </div>
        """,
        unsafe_allow_html=True,
    )

    # Main info card
    st.markdown("### üí≥ Th√¥ng Tin Ch√≠nh")

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("üí∞ Gi√° b√°n", f"{item['price']:.1f} tri·ªáu VNƒê")
    col2.metric("üìè S·ªë km ƒë√£ ƒëi", f"{item['km_driven']:,} km")
    col3.metric("üìÖ NƒÉm ƒëƒÉng k√Ω", f"{int(item['registration_year'])}")
    col4.metric("üè∑Ô∏è Lo·∫°i xe", item["vehicle_type"])

    st.markdown("---")

    # Detailed info
    st.markdown("### üìã Th√¥ng Tin Chi Ti·∫øt")

    col_x, col_y = st.columns(2)

    with col_x:
        st.markdown(
            f"""
        - **üè¢ Th∆∞∆°ng hi·ªáu:** {item['brand']}
        - **üèçÔ∏è Model:** {item['model']}
        - **‚öôÔ∏è Dung t√≠ch ƒë·ªông c∆°:** {item['engine_capacity']}
        """
        )

    with col_y:
        st.markdown(
            f"""
        - **üåç Xu·∫•t x·ª©:** {item['origin']}
        - **üìç ƒê·ªãa ƒëi·ªÉm:** {item['location']}
        - **üè∑Ô∏è Ph√¢n lo·∫°i:** {item['vehicle_type']}
        """
        )

    st.markdown("---")

    # Description
    st.markdown("### üìù M√¥ T·∫£ Chi Ti·∫øt")
    if pd.notna(item["description_norm"]) and item["description_norm"]:
        st.write(item["description_norm"])
    else:
        st.info("Kh√¥ng c√≥ m√¥ t·∫£ chi ti·∫øt")

    st.markdown("---")
    st.markdown("---")

    # Recommendations section
    st.markdown("## üéØ Xe T∆∞∆°ng T·ª± B·∫°n C√≥ Th·ªÉ Quan T√¢m")
    st.markdown("")

    recs = get_recommendations(item_position, model, df, top_k=3)

    # Display as cards
    cols = st.columns(3)

    for i, (idx, row) in enumerate(recs.iterrows()):
        with cols[i]:
            with st.container():
                st.markdown(
                    f"""
                <div style="
                    border: 2px solid #e0e0e0;
                    border-radius: 10px;
                    padding: 20px;
                    background-color: #f9f9f9;
                    height: 100%;
                ">
                </div>
                """,
                    unsafe_allow_html=True,
                )

                st.markdown(f"### {row['brand']} {row['model']}")

                st.markdown(f"**üí∞ Gi√°:** {row['price']:.1f} tri·ªáu VNƒê")
                st.markdown(f"**üìè S·ªë km:** {row['km_driven']:,} km")
                st.markdown(f"**üìÖ NƒÉm ƒëƒÉng k√Ω:** {int(row['registration_year'])}")
                st.markdown(f"**üè¢ Th∆∞∆°ng hi·ªáu:** {row['brand']}")
                st.markdown(f"**‚öôÔ∏è Dung t√≠ch:** {row['engine_capacity']}")
                st.markdown(f"**üåç Xu·∫•t x·ª©:** {row['origin']}")
                st.markdown(f"**üìç ƒê·ªãa ƒëi·ªÉm:** {row['location']}")

                similarity_pct = row["similarity"] * 100
                st.markdown(
                    f"""
                <div style="
                    background-color: #4CAF50;
                    color: white;
                    padding: 5px 10px;
                    border-radius: 5px;
                    text-align: center;
                    margin: 10px 0;
                ">
                    üéØ ƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity_pct:.1f}%
                </div>
                """,
                    unsafe_allow_html=True,
                )

                if st.button(
                    "üëÅÔ∏è Xem chi ti·∫øt",
                    key=f"rec_{int(row['position'])}_{i}",
                    use_container_width=True,
                ):
                    st.session_state["selected_position"] = int(row["position"])
                    st.session_state["scroll_to_top"] = True
                    st.rerun()


# Load model
model, df, cluster_model = load_model()

# Initialize session state
if "page" not in st.session_state:
    st.session_state["page"] = "about"
if "selected_position" not in st.session_state:
    st.session_state["selected_position"] = None
if "last_query" not in st.session_state:
    st.session_state["last_query"] = ""
if "search_results" not in st.session_state:
    st.session_state["search_results"] = None
if "scroll_to_top" not in st.session_state:
    st.session_state["scroll_to_top"] = False

# Sidebar navigation
with st.sidebar:
    st.markdown("## üß≠ ƒêi·ªÅu H∆∞·ªõng")

    if st.button(
        "üìñ Gi·ªõi Thi·ªáu",
        use_container_width=True,
        type="primary" if st.session_state["page"] == "about" else "secondary",
    ):
        st.session_state["page"] = "about"
        st.session_state["scroll_to_top"] = True
        st.rerun()

    if st.button(
        "üîç T√¨m Ki·∫øm",
        use_container_width=True,
        type="primary" if st.session_state["page"] == "search" else "secondary",
    ):
        st.session_state["page"] = "search"
        st.session_state["scroll_to_top"] = True
        st.rerun()

    st.markdown("---")
    st.markdown("### üìä Th·ªëng K√™ Nhanh")
    st.metric("T·ªïng s·ªë xe", f"{len(df):,}")
    st.metric("S·ªë h√£ng", f"{df['brand'].nunique()}")
    st.metric("S·ªë d√≤ng xe", f"{df['model'].nunique()}")

# Check if need to scroll to top
if st.session_state.get("scroll_to_top", False):
    scroll_to_top()
    st.session_state["scroll_to_top"] = False


# ==============================
# üîß DEBUG HELPER
# ==============================
if st.sidebar.checkbox("üîß Debug Mode"):
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üîç Debug Info")
    
    st.sidebar.write(f"**DF Shape:** {df.shape}")
    st.sidebar.write(f"**Clusters:** {df['cluster_id'].nunique()}")
    
    # Test feature building
    if st.sidebar.button("Test Feature Matrix"):
        try:
            fb = FeatureBuilder()
            test_df = df.head(5)
            df_proc = fb.preprocess_df(test_df)
            X_test = fb.build_feature_matrix(df_proc)
            
            st.sidebar.success(f"‚úÖ Shape: {X_test.shape}")
            st.sidebar.write("**Feature names:**")
            st.sidebar.code([
                "price_minmax", "log_km", "engine_cc", "engine_class",
                "vehicle_type_num", "power_ratio", "xe_pkl", "xe_zin"
            ])
            st.sidebar.write("**Sample row:**")
            st.sidebar.code(X_test[0])
            
        except Exception as e:
            st.sidebar.error(f"‚ùå Error: {e}")


# Route pages
if st.session_state["page"] == "about":
    show_about_page()
elif st.session_state["page"] == "search":
    show_search_page()
elif st.session_state["page"] == "detail":
    show_detail_page()

# Footer
st.markdown("---")
st.markdown(f"*H·ªá th·ªëng g·ª£i √Ω xe m√°y - T·ªïng s·ªë xe: {len(df):,}*")